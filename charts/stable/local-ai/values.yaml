image:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0@sha256:e95de574f4197653e8018f4ee779ae07c5270f85c9da39b520f8ca22a44b5fdc
ffmpegImage:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-ffmpeg-core@sha256:178d1f2cb53fba46c025584760616872fe92c3b338bb18e5099f1db859652a5c
cublasCuda12Image:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-cublas-cuda12-core@sha256:8b7d0a67a50a417bb15f89981a781fb9ae1f61608c8c8ee75c3a3ff363b22c3d
cublasCuda12FfmpegImage:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-cublas-cuda12-ffmpeg-core@sha256:0cee2d9b5e515e9ffdfd67d435e620438d2aa620f4f416d0644e20554fd7ff5a
cublasCuda11Image:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-cublas-cuda11-core@sha256:a4fa1281d14ecd0b8c4ab23911b1b96e1423a4d082754d778205f6ca944abc9f
cublasCuda11FfmpegImage:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-cublas-cuda11-ffmpeg-core@sha256:1337ab3d1b5897287df4c25360d82ff1bbd98e4988a7061f57b713cd7d429cec
allInOneCuda12Image:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-aio-gpu-nvidia-cuda-12@sha256:529549e7fb8e93dbe6f336dc2854ebf1b4e989948e53029b90eb670e2b08df83
allInOneCuda11Image:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-aio-gpu-nvidia-cuda-11@sha256:55cae9206dc8dcc4740f854ef1f17bb19a1d639333673d88de597303e520fef1
allInOneCpuImage:
  repository: docker.io/localai/localai
  pullPolicy: IfNotPresent
  tag: v2.17.0-aio-cpu@sha256:e06e1f8af3f7a64fcdef8e34bcb5dbb3447ab4e800a99fc99a9a925057521988
securityContext:
  container:
    runAsNonRoot: false
    readOnlyRootFilesystem: false
    runAsUser: 0
    runAsGroup: 0
service:
  main:
    ports:
      main:
        protocol: http
        port: 8080
localai:
  # Specify a build type. Available: cublas, openblas, clblas.
  build_type: "openblas"
  debug: false
  cors: true
  cors_allow_origins: "*"
  galleries: []
  #  - name: model-gallery
  #    url: github:go-skynet/model-gallery/index.yaml
  preload_models: []
  #    url: github:go-skynet/model-gallery/gpt4all-j.yaml
  # UPLOAD_LIMIT
workload:
  main:
    podSpec:
      containers:
        main:
          probes:
            liveness:
              enabled: true
              type: http
              path: /readyz
            readiness:
              enabled: true
              type: http
              path: /readyz
            startup:
              enabled: true
              type: tcp
          imageSelector: image
          env:
            ADDRESS: ":{{ .Values.service.main.ports.main.port }}"
            MODELS_PATH: "{{ .Values.persistence.models.mountPath }}"
            IMAGE_PATH: "{{ .Values.persistence.images.mountPath }}"
            BUILD_TYPE: "{{ .Values.localai.build_type }}"
            # breaks chart if true, keep it false.
            REBUILD: false
            DEBUG: "{{ .Values.localai.debug }}"
            CORS: "{{ .Values.localai.cors }}"
            GALLERIES: "{{ toJson .Values.localai.galleries }}"
            PRELOAD_MODELS: "{{ toJson .Values.localai.preload_models }}"
            CORS_ALLOW_ORIGINS: "{{ .Values.localai.cors_allow_origins }}"
persistence:
  models:
    enabled: true
    mountPath: "/models"
  images:
    enabled: true
    mountPath: "/images"
portal:
  open:
    enabled: false
updated: true
